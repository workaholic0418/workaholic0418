{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rock_scissor_paper_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1V4U3pz5oxroXN3eOlbvX6CLPzuXm2Sb0",
      "authorship_tag": "ABX9TyPy+kLs7VKrQ+ea3Zg9eRUi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raziel-JKM/Practice/blob/main/ai/EX-1/rock_scissor_paper_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDygYgWI3o1R"
      },
      "source": [
        "#가위바위보 분류기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr2r5YRC6ptK"
      },
      "source": [
        "from PIL import Image\n",
        "import os, glob"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb1ITVbqgcJ_"
      },
      "source": [
        "#1. 이미지 사이즈 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmHCBjhX7d5C",
        "outputId": "b0eeed9d-9995-493d-a785-61d937057a59"
      },
      "source": [
        "#이미지의 크기가 28x28  변경\n",
        "import os\n",
        "\n",
        "def resize_images(img_path):\n",
        "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
        "    \n",
        "\tprint(len(images), \" images to be resized.\")\n",
        "\n",
        "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
        "\ttarget_size=(28,28)\n",
        "\tfor img in images:\n",
        "\t\told_img=Image.open(img)\n",
        "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
        "\t\tnew_img.save(img, \"JPEG\")\n",
        "    \n",
        "\tprint(len(images), \" images resized.\")\n",
        "\t\n",
        "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
        "image_dir_path1 = \"/content/drive/MyDrive/Data/train/scissor\"\n",
        "#image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
        "resize_images(image_dir_path1)\n",
        "\n",
        "print(\"가위 이미지 resize 완료!\")\n",
        "\n",
        "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
        "image_dir_path2 = \"/content/drive/MyDrive/Data/train/rock\"\n",
        "resize_images(image_dir_path2)\n",
        "\n",
        "print(\"바위 이미지 resize 완료!\")\n",
        "\n",
        "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
        "image_dir_path3 = \"/content/drive/MyDrive/Data/train/paper\"\n",
        "resize_images(image_dir_path3)\n",
        "\n",
        "print(\"보 이미지 resize 완료!\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "400  images to be resized.\n",
            "400  images resized.\n",
            "가위 이미지 resize 완료!\n",
            "400  images to be resized.\n",
            "400  images resized.\n",
            "바위 이미지 resize 완료!\n",
            "400  images to be resized.\n",
            "400  images resized.\n",
            "보 이미지 resize 완료!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmcwTX4GghBz"
      },
      "source": [
        "- 데이터 셋 100개로는 부족해서 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKKtBXxCDlzm"
      },
      "source": [
        "#가위바위보의 경우 3개의 클래스 즉, 가위: 0, 바위: 1, 보: 2 로 라벨링\n",
        "import numpy as np\n",
        "\n",
        "def load_data(img_path, number_of_data=1600):  # 가위바위보 이미지 개수 총합에 주의\n",
        "    # 가위 : 0, 바위 : 1, 보 : 2\n",
        "    img_size=28\n",
        "    color=3\n",
        "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성\n",
        "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
        "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
        "\n",
        "    idx=0\n",
        "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=0   # 가위 : 0\n",
        "        idx=idx+1\n",
        "\n",
        "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=1   # 바위 : 1\n",
        "        idx=idx+1  \n",
        "    \n",
        "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
        "        img = np.array(Image.open(file),dtype=np.int32)\n",
        "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
        "        labels[idx]=2   # 보 : 2\n",
        "        idx=idx+1\n",
        "        \n",
        "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
        "    return imgs, labels\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmHZi9P-7pya",
        "outputId": "30996189-0a23-475c-8e06-259320c3622e"
      },
      "source": [
        "image_dir_path = \"/content/drive/MyDrive/Data/train/\"\n",
        "(x_train, y_train)=load_data(image_dir_path)\n",
        "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
        "\n",
        "print(\"x_train shape: {}\".format(x_train.shape))\n",
        "print(\"y_train shape: {}\".format(y_train.shape))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습데이터(x_train)의 이미지 개수는 1200 입니다.\n",
            "x_train shape: (1600, 28, 28, 3)\n",
            "y_train shape: (1600,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "ca3C3Bfj7zAK",
        "outputId": "4f21efb3-ba5f-49a6-fb93-785d19cf67ee"
      },
      "source": [
        "#잘 적용 되었는지 출력\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_train[0])\n",
        "print('라벨: ', y_train[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "라벨:  0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAY0UlEQVR4nO2dXWycZ5mG72d+PP5N/JvEcdKklLar0C4BZbuVQIjSBUoPtsABogeoK6ENByCBxMEi9oAeVqsFxMEuS9hWFJYtYgXd9qAC2lC2S7sLdbuhTX/SJM0PSZ3Eju34d2Y8M88eeIpC8Xu/xmPPWLz3JVkef8+83/f6m+/255n7fZ7H3B1CiD99Mq2egBCiOUjsQiSCxC5EIkjsQiSCxC5EIuSaebDBgUHfu/uaYLxUXKTji6XSmmIAUCzzeMyTsIwFY9Vqbc1jASCT4X9z2/J5Gs/lwi+j1/hvFnNjjE8dBv6EKtl97NjR1yQSZ8+IHtv5axo/b7HZrd0FYyOvTE9jcWFhxYM3JHYzuwPANwBkAfyru9/Hnr939zUY/flTwfjxV1+hx3v15PFg7NjJE3Tsa6dfp/GK8ZOf7SgEY7Nzc3RsW0c7jbe38/iu4Z00PjQ4GIxVSmU6NhZvy/JLJGv8D9V0NRuMLS0t0bG1Ghdc7I9klgguduxisUjjS0v85pGP/IFuxPKuInxevnf/t4OxNf8bb2ZZAP8E4CMA9gG428z2rXV/QoiNpZH37LcAOOHur7t7GcAPANy1PtMSQqw3jYh9BMBvr/r5XH3b72FmB81s1MxGxy9PNHA4IUQjbPin8e5+yN0PuPuBoYHwe0shxMbSiNjPA9h91c+76tuEEJuQRsT+LIDrzexaM2sD8EkAj67PtIQQ682arTd3r5jZ5wD8FMvW2wPu/hIbU6tWMDs5GYzHrJTt27cHYwsRH31qfpbGpyPxWi48N+ZzA8BcxJqLxWNUq9VgrLu9g44t5Nv4ziOvSbHIzzuynTxOiFlvsbgT6809fM4AIEdebwBYvr+FYa/J8vHD1lvM468xC584eg357O7+GIDHGtmHEKI5aLmsEIkgsQuRCBK7EIkgsQuRCBK7EIkgsQuRCE3NZ3d3VCqVYDzms3d0hD3jLVu20LEDAwN831u6aZyluM7Nz9Oxl2emaXxmZobGZ2cjawCWwue0d+tWOnaon5+XthxP1Zxd4L97rpv40RapAxDxwmNednUDKyfH0tWr1fBrEqMayXVnNQqcjNWdXYhEkNiFSASJXYhEkNiFSASJXYhEkNiFSISmWm/ZbA59fX3BeKzc89Rc2KIqRUpJx6p97hziFtTAcDi9tlzjFtArx16l8Ww2XIEVACYmeDmvi5Ph+JW5iG0XsadY5VoAyLXx87pI0ndj5ZZjKayNVKeNl3rmRNNvfe3WWy1mvbHXjMR0ZxciESR2IRJBYhciESR2IRJBYhciESR2IRJBYhciEZrqsyObAXp6guG+iM9eqoW9y/GpcIlqYBVtkdt4aWCWIptrD6e/AkAh0sV17OIFGj9z5gyNnzx5Mhh74xzv23H58mUa7+/vp/FCJAW2uzOcYhvrXhtbGxFLcaU+ezZWKjrSijpy7Nj1xtJY4+2kWYormRPdqxDiTwaJXYhEkNiFSASJXYhEkNiFSASJXYhEkNiFSITm+uzuAMk7bycePADs7gz7sjORksZvTFyKTG3t3masZfONN95I4wNDPGe8P5JTXiAltmPtoM+ePUvjE5Pch4954SP94ToAvb29dGxXVxeNR/PhSSw275gPH/PZK772fPmGfHZ2na55RgDM7DSAWQBVABV3P9DI/oQQG8d63Nlvc3deSkUI0XL0nl2IRGhU7A7gZ2b2nJkdXOkJZnbQzEbNbHQ8UktNCLFxNCr297r7uwF8BMBnzex9b32Cux9y9wPufiBWvFAIsXE0JHZ3P1//fgnAwwBuWY9JCSHWnzWL3cy6zKznzccAPgTg6HpNTAixvjTyafx2AA/Xvc4cgH9395+wAV6tojRP6ohHvM0asS5jXveWLt6SubCVx/u3hj3hWD57zJON1Y0fjLz9YT5+zGf3iFddXFig8dh5X5gO1/pvz/Ox+cj10ICVjZrz+gWZyGtScV43PpbP7mTysbrxYC2bN8Jnd/fXAbxzreOFEM1F1psQiSCxC5EIErsQiSCxC5EIErsQidDUFFcHsFQNl4Oeu8JtIpbGGiuJXChwe2xkZITGd+3aFYxVIxYQKxsMAMjwHbSXyzTO7JZt27bRsbEy1cVikcYrkdbFWdLOOhOxr5yUDl8+Nrc0q2RuVUTs0By35mLWW8ySZLYhs+WW4+x6UstmIZJHYhciESR2IRJBYhciESR2IRJBYhciESR2IRKhqT57JpPh5YFj5XuJ/djn3Dc9dZb7ydl27qtuJWWPv/vQ9+nYd9x0E43/9V0fo/Gp2SkaZwyRVtNAPL02Vu55dnaWxvu3bAnGLLL+YG7mCo1bll++7Z3hEttLS0t07EJxkcZzbbzd9GKJr08wC5/3WHosizMPXnd2IRJBYhciESR2IRJBYhciESR2IRJBYhciESR2IRKhuS2bzWBt4Va5XblI+V7iy84s8pbNsTa4i4vcVz196lQw9vyzo3TsQqQcc6yl8zXX7qXxgb7+8Nhdu+nYndvCLZUB4MKlizQ+H/HZjZ32Jb42oljmXvVShY9nXrdH1nRksrylczbPryfmowO8ZXSs9kI+F45nMsS/p3sVQvzJILELkQgSuxCJILELkQgSuxCJILELkQgSuxCJ0HSfHcRftEgL317iw8fyj3fs2EHj24Z5vLM7nIc/smOYjn35Ny/S+Oj1v6Lx4cjcF2fC9fZrJZ637VVe/9yq3E/uyHNP2EmL7gxZcwEAWfD66byqPPf4cxl+7Ay5TgGgrT2cKw8Aucj4PDlvzIMH+NxZrnv0zm5mD5jZJTM7etW2fjN73MyO17/3xfYjhGgtq/k3/jsA7njLti8BOOzu1wM4XP9ZCLGJiYrd3Z8CMPmWzXcBeLD++EEAH13neQkh1pm1fkC33d3H6o8vAAgusDazg2Y2amaj4xMTazycEKJRGv403pczTIIfhbj7IXc/4O4HhgYHGz2cEGKNrFXsF81sGADq3y+t35SEEBvBWsX+KIB76o/vAfDI+kxHCLFRRH12M3sIwPsBDJrZOQBfAXAfgB+a2acBnAHwidUcrFatYnZmOhivVCL9uEk8Vr/cjHu2W0h9c4D3Z/+r2z5Ax/7zt/6Fxl8/foLGq0Xen71WDnvp1RIfW5nn6xMqxRKNd7Zxn312LpwPvyVSk76rg/QYANCR5a9pvqMzGLNI7QSP1KTPt/E+A+2RuWcj+fKMaiW8NoKVbYiK3d3vDoRuj40VQmwetFxWiESQ2IVIBIldiESQ2IVIBIldiERocoorltNcA8zN83LQrM3u7Fw4lRKIW3NTE5dpfJiUXL7h7dfTsVsiNszlC3xNUsw+GxkKz628yMsxdxN7CgAmeQYscpGWzzVSLjpr/F5TKPC2yIjYY5l2YgtGxrL24ACQscj4SGpwjpSyjrXRrhF/jVnMurMLkQgSuxCJILELkQgSuxCJILELkQgSuxCJILELkQhN9dkzmSx6enqC8VKJp1OyVraxtsgx5iMe/xzx8ft6eHrs2/bspfGzZ8/S+IvPH6HxW2+9NRjLR/6eZyM+eibiFxfa+SXU090djG3tDl8LAE9RBYBiLVZMOuxXOym5DACZXKQUdDufW6yddK4QTpHtaufrMjLk98qS9QO6swuRCBK7EIkgsQuRCBK7EIkgsQuRCBK7EIkgsQuRCE312R2OioeN3WykhW+eeKOxUtGslS0AtBMPHwDyufCpiuV0/+Utt9D4sVdfpfH/+sUvaHzPNdcEY7E8/tICLyVdW+Jedsynby+E/ejOzrAHDwA5lo8OAJG5VXPkmsjzUtAWiecipaTbCvx66yA1DnJZvu+lEvu9w+sidGcXIhEkdiESQWIXIhEkdiESQWIXIhEkdiESQWIXIhGa6rNbJoNce7gWeB/xsgEAJB6r+75161YaHxkZofG+HTvCwSo3m2/a9w4aL0Q83XNnf0vjqIW91baIH8zWDwDLbbYZxUXu0xeL4br11ci+C5G1EbnI3I347B5ZG+GRdRvLTRDCxNYQGPndYrUVpievBGNLZO1B9M5uZg+Y2SUzO3rVtnvN7LyZHal/3RnbjxCitazm3/jvALhjhe1fd/f99a/H1ndaQoj1Jip2d38KwGQT5iKE2EAa+YDuc2b2Qv3f/L7Qk8zsoJmNmtno+Ph4A4cTQjTCWsX+TQDXAdgPYAzAV0NPdPdD7n7A3Q8MDQ2t8XBCiEZZk9jd/aK7V929BuDbAHhalxCi5axJ7GY2fNWPHwNwNPRcIcTmIOqzm9lDAN4PYNDMzgH4CoD3m9l+LCfPngbwmdUczJeWsHQx3It8dpHXfrf2sDd6dpzXXp+q8bzui9WwdwkApfETwVhfN68bv+v6nTR+3dt30fjYmdM0/n/PPBmMffADt9OxxUvnaXxnN88pH5/in8P4wN5gzLbtoWMvRa6HCl9CgCzx4Z30OAeA3h6+LqMyz/ves/7rAJAn9fj/89/+g449c+ZMMDZXmw7Pie4VgLvfvcLm+2PjhBCbCy2XFSIRJHYhEkFiFyIRJHYhEkFiFyIRmltK2h2VSjgFL5byWF4It3SOtWweGxuj8UykjHVn+w3BWNH4sXf0D9L4hz/8YRr/zqFv0fiTT4att5sj6bWx1N9YO+lCpOxxjtiSuVyknLPxFt6ZSBpqPh9+TWs1npZsJG0YiFt3sQTZyclwuklMB/29wdXpWLwStph1ZxciESR2IRJBYhciESR2IRJBYhciESR2IRJBYhciEZrqs2cyWXR0kla1Ea/7Silctniof4COnZrhKaxDA3z8Nbt2B2OTly7Ssc88/TSN3/wO7oXv//N30vjhn/wsHHviCToWEb+4EGllXSpxL7y9LTye+eAA0NUVvlYAoFRdovHyUtivXlriYwtZLo2OyHnp6gi3qgaA6Uo41Xvntm10bOc1HcHY5JHwfnVnFyIRJHYhEkFiFyIRJHYhEkFiFyIRJHYhEkFiFyIRmuqzA0593Wykje5SuRzeM08BRlsu4ulGfNFqOezLPvPL/6Fjf/LIIzT+Fzfvp/GFOd4Wuac73B74F4d/Tsf29vbyfffyfPcr0+HSxQCw623hFt2VUri2AQCUyDkHgOJS+HoAgHx7+DXv6O6hYzvI+gAA6IqsEegh60kAYLAvnJP+7v3v4scuhOsAPHvs18GY7uxCJILELkQiSOxCJILELkQiSOxCJILELkQiSOxCJEJzffZsFiD+Zibyp6enHM6dri1xzzbmw/e0c589a+HJTY9fpmOnIvFHf/wwjedrvAr5YH9/MLZA6ogDwNwMj7e1RerCk7bIAFAktf6vzMzRsZOzvAbBArkeAGBoZzgvfHj7EB27uMjXNpSm+dyqs/M0nimHr9fByNqGBVabgaxjid7ZzWy3mT1pZi+b2Utm9vn69n4ze9zMjte/h1cJCCFazmr+ja8A+KK77wNwK4DPmtk+AF8CcNjdrwdwuP6zEGKTEhW7u4+5+/P1x7MAXgEwAuAuAA/Wn/YggI9u1CSFEI3zR31AZ2Z7AbwLwK8AbHf3NxuoXQCwPTDmoJmNmtno+PhEA1MVQjTCqsVuZt0AfgTgC+4+c3XMl7vcrfjJgLsfcvcD7n5gaIg3OBRCbByrEruZ5bEs9O+7+4/rmy+a2XA9PgwgXNZSCNFyotabmRmA+wG84u5fuyr0KIB7ANxX/87zOAFUiiVcPnEiGM+387TC8StTwdipU6f42Olwi1wAmL3uOhrv6wlbKb1bwm2JAWDH4IrvcH5HrZtbLdMXx2l84lI4nsvwVMxYOefZWW7NZSJ+aW9P+Hfr2srP294stxxPn+PtpJ2Mzxi/9HN5/nvFUljzFd4Sum9rOLV4S57bnccmydthYr2txmd/D4BPAXjRzI7Ut30ZyyL/oZl9GsAZAJ9Yxb6EEC0iKnZ3/yXCveVvX9/pCCE2Ci2XFSIRJHYhEkFiFyIRJHYhEkFiFyIRmpriambIZcKHXFjgaYVhU4C3BgaA3i3cy65GWvieeO1kMDY3PROMAUClxEse7xjgLXp7Czz99tTJ14OxzvZwKWcAqEZaNs8vLNB4Ns8vobHzF4KxazvDJbABoJd40QBgJO0YAObIGoHuznDbYwDIrbwg9HcUOni8WoyUwa6Gc67LVZ6u/crRo8EYS83VnV2IRJDYhUgEiV2IRJDYhUgEiV2IRJDYhUgEiV2IRGiqz57NZrF1YCAYnx87T8fXauEcYebfA0CWePQAcPzYazT+v08/E4z95tnn6Nj9+/bR+LlTZ2h8z67dNH77bbcFY+0Rn/3oyy/T+JVZvoagq4d75SWy/sEj5b/LRV4qOtZWeWRkZzB20838NZmZ4vUPFqfDtRUAoK3Ca5cXamGfvjTF22CXF4vBmHtYI7qzC5EIErsQiSCxC5EIErsQiSCxC5EIErsQiSCxC5EITfXZa7Ua5olv29vL85d9ntcwZxQK3G/u6Qm3kgaAhblw3fiR4bCfCwAXx3j/jIFu7lXPRtoDT0+EW0LnIy2X2zp4fM+ePTS+tY+/ZrM+Eoz1RFoT924Pr8kAgB27+XmfWQi/ZpcuhfPsAcAiOeXFYtjrBgAQHx3gr9lSZG3D7l3h37vtzIvBmO7sQiSCxC5EIkjsQiSCxC5EIkjsQiSCxC5EIkjsQiTCavqz7wbwXQDbATiAQ+7+DTO7F8DfAnizOfiX3f0xtq9MLoeuwXCN9CsTvA856xVeLvPa7JaL9NuO+OxbSZ/xmQme+5yNeK61Co8XK9zTLZJa4XzPQI2n+QNZft4KkfrrfTvCNe/L5cjvtcT7CJSN90CfmmfrE/jYjEVekxm+5mOgg9f6L8+Ec9YzZV5zntV1YKxmUU0FwBfd/Xkz6wHwnJk9Xo993d3/cU1HFkI0ldX0Zx8DMFZ/PGtmrwAIL4sSQmxK/qj37Ga2F8C7APyqvulzZvaCmT1gZn2BMQfNbNTMRscnJhqarBBi7axa7GbWDeBHAL7g7jMAvgngOgD7sXzn/+pK49z9kLsfcPcDQ4OD6zBlIcRaWJXYzSyPZaF/391/DADuftHdq75c4e7bAG7ZuGkKIRolKnYzMwD3A3jF3b921fbhq572MQDh1pJCiJazmk/j3wPgUwBeNLMj9W1fBnC3me3HsrtzGsBnYjsqF4s4fexYML5Y4lbMFElxPX32t3RsJsc9pn2Rcs833HBDMDZ+7g06tlwKp1oCQJW07wWAjPO5Z7PZcCzHX+Jq5M99KZLquRSJv3H2bDBW6Ob2VMeVLhovR+yx2XL4vLd38jLUsVbXXuP2WCyF1old2unh1xMAqsSqZR24V/Np/C+xcmN06qkLITYXWkEnRCJI7EIkgsQuRCJI7EIkgsQuRCJI7EIkQlNLSc/MzODxw08E4zf82Y10fHt32Hc9c4a3PZ5fWKDxj3/84zTOfPZf//fTdOxixEePkYt45YVC2DPu7OFetuW4p1usRtItIymyJ18Npy23lyNpoM5bNtciactLHp57oSNPx7ZFSnBnI+ftwkVePjxXCl8TuTyfW5W0ZXaS1Kw7uxCJILELkQgSuxCJILELkQgSuxCJILELkQgSuxCJYM4SYNf7YGbjAK42xAcBbNbCdJt1bpt1XoDmtlbWc2573H1opUBTxf4HBzcbdfcDLZsAYbPObbPOC9Dc1kqz5qZ/44VIBIldiERotdgPtfj4jM06t806L0BzWytNmVtL37MLIZpHq+/sQogmIbELkQgtEbuZ3WFmx8zshJl9qRVzCGFmp83sRTM7YmajLZ7LA2Z2ycyOXrWt38weN7Pj9e8r9thr0dzuNbPz9XN3xMzubNHcdpvZk2b2spm9ZGafr29v6bkj82rKeWv6e3YzywJ4DcAHAZwD8CyAu9395aZOJICZnQZwwN1bvgDDzN4HYA7Ad939pvq2fwAw6e731f9Q9rn7322Sud0LYK7Vbbzr3YqGr24zDuCjAP4GLTx3ZF6fQBPOWyvu7LcAOOHur7t7GcAPANzVgnlsetz9KQCTb9l8F4AH648fxPLF0nQCc9sUuPuYuz9ffzwL4M024y09d2ReTaEVYh8BcHWvpnPYXP3eHcDPzOw5MzvY6smswHZ3H6s/vgBgeysnswLRNt7N5C1txjfNuVtL+/NG0Qd0f8h73f3dAD4C4LP1f1c3Jb78HmwzeaerauPdLFZoM/47Wnnu1tr+vFFaIfbzAHZf9fOu+rZNgbufr3+/BOBhbL5W1Bff7KBb/84rGzaRzdTGe6U249gE566V7c9bIfZnAVxvZteaWRuATwJ4tAXz+APMrKv+wQnMrAvAh7D5WlE/CuCe+uN7ADzSwrn8HpuljXeozThafO5a3v7c3Zv+BeBOLH8ifxLA37diDoF5vQ3Ab+pfL7V6bgAewvK/dUtY/mzj0wAGABwGcBzAEwD6N9HcvgfgRQAvYFlYwy2a23ux/C/6CwCO1L/ubPW5I/NqynnTclkhEkEf0AmRCBK7EIkgsQuRCBK7EIkgsQuRCBK7EIkgsQuRCP8PgK4NRvr/KLMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoFeZXxL8lAd",
        "outputId": "30738584-d436-4953-cd3b-2a017f231785"
      },
      "source": [
        "print(x_train.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1600, 28, 28, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXeJHvt3GgO4",
        "outputId": "f7779c0f-1c10-42ef-f4e2-e6c9c282d108"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#train 데이터를 훈련셋 검증셋 80%, 20%로 랜덤하게 변경\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_norm, y_train, test_size=0.2, shuffle=True, random_state=12)\n",
        "\n",
        "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1280, 28, 28, 3) (320, 28, 28, 3) (1280,) (320,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsuu2lIu71k5"
      },
      "source": [
        "#네트워크 설계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plYeF-ZGTkGA",
        "outputId": "c31899a4-77e8-45ee-be61-7538ecd56c77"
      },
      "source": [
        "#이미지 제너레이터\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range=40,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory('/content/drive/MyDrive/Data/train',\n",
        "                                                 target_size = (28, 28),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical',subset='training')\n",
        "val_gen  = train_datagen.flow_from_directory('/content/drive/MyDrive/Data/test',\n",
        "                                                 target_size = (28 , 28),\n",
        "                                                  batch_size = 32,\n",
        "                                                 class_mode = 'categorical',subset='validation')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1200 images belonging to 3 classes.\n",
            "Found 0 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bdcs0qJcY4_K",
        "outputId": "6e6d6c1c-3526-46f7-e83f-16c00c75be03"
      },
      "source": [
        "import tensorflow as tf\n",
        "# Initialising the CNN\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Step 1 - Convolution\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[28, 28, 3]))\n",
        "# Step 2 - Pooling\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "# Adding convolutional layer\n",
        "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "# Step 3 - Flattening\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "# Step 4 - Full Connection\n",
        "model.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "# Step 5 - Output Layer\n",
        "model.add(tf.keras.layers.Dense(units=3, activation='softmax'))\n",
        "# Compiling the CNN\n",
        "model.compile(optimizer = 'adam', \n",
        "            loss = 'categorical_crossentropy', \n",
        "            metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 5, 5, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 800)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               102528    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 387       \n",
            "=================================================================\n",
            "Total params: 113,059\n",
            "Trainable params: 113,059\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op2n45-KZAnq",
        "outputId": "72077a51-3474-4123-dc65-0b68aa2e1010"
      },
      "source": [
        "result  = model.fit(x = train_gen, validation_data = val_gen, epochs = 100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "38/38 [==============================] - 4s 86ms/step - loss: 5.8565 - accuracy: 0.3700\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 1.0854 - accuracy: 0.4350\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 1.0569 - accuracy: 0.4642\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 1.0423 - accuracy: 0.4542\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 1.0213 - accuracy: 0.4758\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 0.9717 - accuracy: 0.5233\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 0.9573 - accuracy: 0.5400\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 0.9181 - accuracy: 0.5808\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 0.9244 - accuracy: 0.5833\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 3s 90ms/step - loss: 0.9269 - accuracy: 0.5717\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.9152 - accuracy: 0.5775\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 0.9543 - accuracy: 0.5108\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 3s 91ms/step - loss: 0.9479 - accuracy: 0.5283\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.9001 - accuracy: 0.5617\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.9484 - accuracy: 0.5283\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.8725 - accuracy: 0.5933\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.8327 - accuracy: 0.6367\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.8144 - accuracy: 0.6358\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.8316 - accuracy: 0.6200\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.8041 - accuracy: 0.6425\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.8576 - accuracy: 0.6108\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.8036 - accuracy: 0.6475\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.7883 - accuracy: 0.6675\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.7800 - accuracy: 0.6667\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.7378 - accuracy: 0.6633\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.7661 - accuracy: 0.6625\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.7695 - accuracy: 0.6683\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.8066 - accuracy: 0.6767\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.7347 - accuracy: 0.6842\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.7802 - accuracy: 0.6550\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.8440 - accuracy: 0.6317\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.7980 - accuracy: 0.6450\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.7805 - accuracy: 0.6392\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.7129 - accuracy: 0.7017\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.6293 - accuracy: 0.7375\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.6986 - accuracy: 0.6992\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.7156 - accuracy: 0.6892\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.6154 - accuracy: 0.7433\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.6407 - accuracy: 0.7350\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.6752 - accuracy: 0.7025\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.5872 - accuracy: 0.7683\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.5744 - accuracy: 0.7733\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.6095 - accuracy: 0.7525\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.5864 - accuracy: 0.7633\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.5590 - accuracy: 0.7675\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.5828 - accuracy: 0.7525\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.5698 - accuracy: 0.7708\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.5374 - accuracy: 0.7775\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.5295 - accuracy: 0.7825\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.5536 - accuracy: 0.7733\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.5465 - accuracy: 0.7825\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.5310 - accuracy: 0.7917\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.4710 - accuracy: 0.8242\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.5912 - accuracy: 0.7525\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.5787 - accuracy: 0.7617\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.5211 - accuracy: 0.8050\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.4738 - accuracy: 0.8058\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 3s 80ms/step - loss: 0.4836 - accuracy: 0.8208\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.4998 - accuracy: 0.7967\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.4920 - accuracy: 0.8100\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.4669 - accuracy: 0.8158\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.4695 - accuracy: 0.8142\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.6039 - accuracy: 0.7425\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 3s 80ms/step - loss: 0.5131 - accuracy: 0.8017\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.4399 - accuracy: 0.8367\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.4315 - accuracy: 0.8358\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.5178 - accuracy: 0.7975\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.4659 - accuracy: 0.8150\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.4789 - accuracy: 0.8108\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.4558 - accuracy: 0.8300\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 3s 82ms/step - loss: 0.3982 - accuracy: 0.8558\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 3s 80ms/step - loss: 0.4142 - accuracy: 0.8375\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.4375 - accuracy: 0.8383\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 3s 81ms/step - loss: 0.4144 - accuracy: 0.8608\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 3s 83ms/step - loss: 0.4478 - accuracy: 0.8225\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.3686 - accuracy: 0.8542\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.3946 - accuracy: 0.8350\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.4141 - accuracy: 0.8433\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 0.4076 - accuracy: 0.8375\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 0.3848 - accuracy: 0.8533\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 0.3780 - accuracy: 0.8575\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 0.4003 - accuracy: 0.8458\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.3906 - accuracy: 0.8442\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 3s 87ms/step - loss: 0.4032 - accuracy: 0.8450\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 3s 91ms/step - loss: 0.3857 - accuracy: 0.8492\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.4059 - accuracy: 0.8400\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 0.3610 - accuracy: 0.8650\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.3792 - accuracy: 0.8533\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.4523 - accuracy: 0.8283\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 3s 89ms/step - loss: 0.4146 - accuracy: 0.8317\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 4s 93ms/step - loss: 0.3855 - accuracy: 0.8625\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.3692 - accuracy: 0.8517\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 3s 91ms/step - loss: 0.3661 - accuracy: 0.8600\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 3s 84ms/step - loss: 0.3867 - accuracy: 0.8625\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.4026 - accuracy: 0.8500\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 3s 90ms/step - loss: 0.4063 - accuracy: 0.8408\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 3s 90ms/step - loss: 0.3373 - accuracy: 0.8650\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 3s 88ms/step - loss: 0.3256 - accuracy: 0.8717\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 3s 85ms/step - loss: 0.3548 - accuracy: 0.8700\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 3s 86ms/step - loss: 0.3301 - accuracy: 0.8825\n"
          ]
        }
      ]
    }
  ]
}